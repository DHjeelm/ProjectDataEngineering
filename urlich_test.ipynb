{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2bba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/09 19:43:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/09 19:43:08 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "\n",
    "\n",
    "# Spark session\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.218:7077\") \\\n",
    "        .appName(\"Scalingtest\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .config(\"spark.executor.memory\",\"2g\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Spark context\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f705c7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hdfs://192.168.2.200:9000/user/ubuntu/lastfm_train/Z'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loop to append file paths for each parent directory\n",
    "root ='hdfs://192.168.2.200:9000/user/ubuntu/lastfm_train/'\n",
    "letters = ['A','B','C','E','G','J','K','L','M','N','O','P','Q','R','S','T','U','W','X','Y','Z']\n",
    "paths=[]\n",
    "for i in letters:\n",
    "    paths.append(root+i)\n",
    "paths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f197fed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#starting timing and run all cells below to measure wall time\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "#read in files from parent directories choose how may by slicing the paths list in the loop\n",
    "data = spark_session.read.option(\"recursiveFileLookup\", \"true\").json(paths[0])\n",
    "for i in paths[1:3]:\n",
    "    temp = spark_session.read.option(\"recursiveFileLookup\", \"true\").json(i)\n",
    "    data = data.union(temp)\n",
    "\n",
    "\n",
    "#data = spark_session.read.json('hdfs://192.168.2.200:9000/user/ubuntu/lastfm_train/B/A/A/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302afffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the tags column\n",
    "from pyspark.sql.functions import flatten\n",
    "dataframe = data.withColumn(\"New tags\", flatten(data.tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22d2a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the numbers from the tags (the numbers are every other element)\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "removeNumbers = udf(lambda lst: lst[0::2], ArrayType(StringType()))\n",
    "\n",
    "dataFrame = dataframe.withColumn(\"Only tags\", removeNumbers(col(\"New tags\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56137a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# Function for determine if a song has been tagged with a tag including \"male\" or \"female\" or both\n",
    "def genderTags(lst):\n",
    "    genderList = []\n",
    "    for element in lst:\n",
    "        if re.search(\"female|Female\", element) and \"female\" not in genderList:\n",
    "            genderList.append(\"female\")\n",
    "            continue\n",
    "        elif re.search(\"male|Male\", element) and \"male\" not in genderList:\n",
    "            genderList.append(\"male\")\n",
    "            continue\n",
    "        \n",
    "    return genderList\n",
    "\n",
    "# Create udf from the above function\n",
    "genderTagUDF = udf(genderTags, ArrayType(StringType()))\n",
    "\n",
    "# Create a new column representing wether a song has been tagged with \"female\", \"male\" or both\n",
    "dataframe = dataFrame.withColumn(\"Gender tag\", genderTagUDF(col(\"Only tags\")))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "966bd2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:===========>                                      (771 + -605) / 3373]\r"
     ]
    }
   ],
   "source": [
    "# Function for removing the gender tag from the tags\n",
    "def removeGenderTags(lst):\n",
    "    tags = []\n",
    "    for element in lst:\n",
    "        if re.search(\"female|Female\", element) or re.search(\"male|Male\", element):\n",
    "            continue\n",
    "        else:\n",
    "            tags.append(element)\n",
    "        \n",
    "        \n",
    "    return tags\n",
    "\n",
    "# Create udf from the above function\n",
    "removeGenderTagUDF = udf(removeGenderTags, ArrayType(StringType()))\n",
    "\n",
    "# Create a new column where the\"female\" and \"male\" tags have been removed from the other tags\n",
    "filteredDF = dataframe.withColumn(\"Tags\", removeGenderTagUDF(col(\"Only tags\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72feaff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with only the tags and the gender tag\n",
    "genderDataFrame = filteredDF.select(\"Tags\", \"Gender tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f90f6d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:===========>                                      (773 + -605) / 3373]\r"
     ]
    }
   ],
   "source": [
    "# Explode the tags column\n",
    "from pyspark.sql.functions import explode\n",
    "genderDataFrame = genderDataFrame.select(genderDataFrame[\"Gender tag\"], explode(genderDataFrame[\"Tags\"]))\n",
    "genderDataFrame = genderDataFrame.withColumnRenamed(\"col\", \"Tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d2cbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the gender tag column\n",
    "genderDataFrame = genderDataFrame.select(explode(genderDataFrame[\"Gender tag\"]), genderDataFrame[\"Tag\"])\n",
    "genderDataFrame = genderDataFrame.withColumnRenamed(\"col\", \"Gender\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "663b35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/09 20:15:08 ERROR TaskSchedulerImpl: Lost executor 14 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:15:16 ERROR TaskSchedulerImpl: Lost executor 15 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:15:25 ERROR TaskSchedulerImpl: Lost executor 16 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:15:30 ERROR TaskSchedulerImpl: Lost executor 17 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:15:30 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 64838 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:15:47 ERROR TaskSchedulerImpl: Lost executor 18 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:15:51 ERROR TaskSchedulerImpl: Lost executor 19 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:15:51 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 65098 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:16:07 ERROR TaskSchedulerImpl: Lost executor 20 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:16:08 ERROR TaskSchedulerImpl: Lost executor 21 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:16:24 ERROR TaskSchedulerImpl: Lost executor 22 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:16:24 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 65546 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:16:24 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 65547 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:16:26 ERROR TaskSchedulerImpl: Lost executor 23 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:16:26 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 65568 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:16:26 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 65569 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:16:41 ERROR TaskSchedulerImpl: Lost executor 24 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:16:41 ERROR TaskSchedulerImpl: Lost executor 25 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:16:55 ERROR TaskSchedulerImpl: Lost executor 26 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:16:55 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 65987 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:16:55 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 65988 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:16:57 ERROR TaskSchedulerImpl: Lost executor 27 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:16:57 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 66021 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:16:57 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 66022 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:17:13 ERROR TaskSchedulerImpl: Lost executor 29 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:17:16 ERROR TaskSchedulerImpl: Lost executor 28 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:17:28 ERROR TaskSchedulerImpl: Lost executor 30 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:17:28 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 66466 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:17:35 ERROR TaskSchedulerImpl: Lost executor 31 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:17:51 ERROR TaskSchedulerImpl: Lost executor 32 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:17:52 ERROR TaskSchedulerImpl: Lost executor 33 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:18:10 ERROR TaskSchedulerImpl: Lost executor 35 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:18:13 ERROR TaskSchedulerImpl: Lost executor 34 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:18:13 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 67156 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:18:28 ERROR TaskSchedulerImpl: Lost executor 36 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:18:29 ERROR TaskSchedulerImpl: Lost executor 37 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:18:44 ERROR TaskSchedulerImpl: Lost executor 38 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/09 20:18:45 ERROR TaskSchedulerImpl: Lost executor 39 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:18:45 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 67689 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:19:00 ERROR TaskSchedulerImpl: Lost executor 41 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:19:00 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 67894 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:19:01 ERROR TaskSchedulerImpl: Lost executor 40 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:19:01 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 67923 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:19:17 ERROR TaskSchedulerImpl: Lost executor 42 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:19:17 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 68200 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:19:17 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 68201 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:19:20 ERROR TaskSchedulerImpl: Lost executor 43 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:19:20 ERROR TaskSchedulerImpl: Ignoring update with state RUNNING for TID 68237 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "22/03/09 20:19:32 ERROR TaskSchedulerImpl: Lost executor 44 on 192.168.2.152: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:19:33 ERROR TaskSchedulerImpl: Lost executor 45 on 192.168.2.54: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/03/09 20:19:33 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 68424 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.\n",
      "ERROR:root:KeyboardInterrupt while sending command.              (0 + 0) / 3373]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find the most frequent tags for \"female\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tagsFemale \u001b[38;5;241m=\u001b[39m genderDataFrame\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfilter(genderDataFrame[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfemale\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTag\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m})\\\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount(Tag)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrequency\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrequency\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtagsFemale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:494\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    476\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find the most frequent tags for \"female\"\n",
    "tagsFemale = genderDataFrame.select(\"Tag\").filter(genderDataFrame[\"Gender\"] == \"female\").groupBy(\"Tag\").agg({\"Tag\": \"count\"})\\\n",
    "        .withColumnRenamed(\"count(Tag)\",\"Frequency\").orderBy(\"Frequency\", ascending=False)\n",
    "\n",
    "tagsFemale.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most frequent tags for \"male\"\n",
    "tagsMale = genderDataFrame.select(\"Tag\").filter(genderDataFrame[\"Gender\"] == \"male\").groupBy(\"Tag\").agg({\"Tag\": \"count\"})\\\n",
    "        .withColumnRenamed(\"count(Tag)\",\"Frequency\").orderBy(\"Frequency\", ascending=False)\n",
    "\n",
    "print(tagsMale.show())\n",
    "print()\n",
    "print(f'execution time in minutes: {(time.time()-start)/60}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c07d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b41a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2e0a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496891bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
